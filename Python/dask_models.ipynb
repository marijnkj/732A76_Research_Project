{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare datasets\n",
    "# ddf = dd.read_csv(r\"C:\\Users\\marij\\Documents\\GitHub\\732A76_Research_Project\\Data\\HIGSS.csv\")\n",
    "\n",
    "# ddf.loc[:40000, :].to_parquet(r\"C:\\Users\\marij\\Documents\\GitHub\\732A76_Research_Project\\Data\\small.parquet\")\n",
    "# ddf.to_parquet(r\"C:\\Users\\marij\\Documents\\GitHub\\732A76_Research_Project\\Data\\medium.parquet\")\n",
    "# dd.concat([ddf, ddf]).to_parquet(r\"C:\\Users\\marij\\Documents\\GitHub\\732A76_Research_Project\\Data\\large.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 partitions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marij\\miniconda3\\envs\\research_project_dask\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medium data\n",
      "75 partitions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marij\\miniconda3\\envs\\research_project_dask\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Large data\n",
      "175 partitions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marij\\miniconda3\\envs\\research_project_dask\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small data\n",
      "1 partitions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marij\\miniconda3\\envs\\research_project_dask\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medium data\n",
      "75 partitions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marij\\miniconda3\\envs\\research_project_dask\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Large data\n",
      "175 partitions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marij\\miniconda3\\envs\\research_project_dask\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small data\n",
      "1 partitions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marij\\miniconda3\\envs\\research_project_dask\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medium data\n",
      "75 partitions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marij\\miniconda3\\envs\\research_project_dask\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Large data\n",
      "175 partitions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marij\\miniconda3\\envs\\research_project_dask\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small data\n",
      "1 partitions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marij\\miniconda3\\envs\\research_project_dask\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medium data\n",
      "75 partitions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marij\\miniconda3\\envs\\research_project_dask\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Large data\n",
      "175 partitions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marij\\miniconda3\\envs\\research_project_dask\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small data\n",
      "1 partitions\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m lin_reg \u001b[38;5;241m=\u001b[39m LinearRegression()\n\u001b[0;32m     22\u001b[0m start_time \u001b[38;5;241m=\u001b[39m perf_counter()   \n\u001b[1;32m---> 23\u001b[0m \u001b[43mlin_reg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m end_time \u001b[38;5;241m=\u001b[39m perf_counter()\n\u001b[0;32m     26\u001b[0m res[j, \u001b[38;5;241m0\u001b[39m, i] \u001b[38;5;241m=\u001b[39m end_time \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Users\\marij\\miniconda3\\envs\\research_project_dask\\Lib\\site-packages\\dask_ml\\linear_model\\glm.py:189\u001b[0m, in \u001b[0;36m_GLM.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    185\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_array(X)\n\u001b[0;32m    187\u001b[0m solver_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_solver_kwargs()\n\u001b[1;32m--> 189\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_coef \u001b[38;5;241m=\u001b[39m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_solvers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msolver_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_intercept:\n\u001b[0;32m    191\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_coef[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\marij\\miniconda3\\envs\\research_project_dask\\Lib\\site-packages\\dask_glm\\utils.py:32\u001b[0m, in \u001b[0;36mnormalize.<locals>.normalize_inputs\u001b[1;34m(X, y, *args, **kwargs)\u001b[0m\n\u001b[0;32m     26\u001b[0m mean \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     27\u001b[0m     mean\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(intercept_idx[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m zeros(mean\u001b[38;5;241m.\u001b[39mshape, \u001b[38;5;28mgetattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_meta\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m     30\u001b[0m )\n\u001b[0;32m     31\u001b[0m Xn \u001b[38;5;241m=\u001b[39m (X \u001b[38;5;241m-\u001b[39m mean) \u001b[38;5;241m/\u001b[39m std\n\u001b[1;32m---> 32\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43malgo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m     33\u001b[0m i_adj \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(out \u001b[38;5;241m*\u001b[39m mean \u001b[38;5;241m/\u001b[39m std)\n\u001b[0;32m     34\u001b[0m out[intercept_idx] \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m i_adj\n",
      "File \u001b[1;32mc:\\Users\\marij\\miniconda3\\envs\\research_project_dask\\Lib\\site-packages\\dask_glm\\algorithms.py:312\u001b[0m, in \u001b[0;36madmm\u001b[1;34m(X, y, regularizer, lamduh, rho, over_relax, max_iter, abstol, reltol, family, **kwargs)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_iter):\n\u001b[0;32m    307\u001b[0m     \u001b[38;5;66;03m# x-update step\u001b[39;00m\n\u001b[0;32m    308\u001b[0m     new_betas \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    309\u001b[0m         delayed(local_update)(xx, yy, bb, z, uu, rho, f\u001b[38;5;241m=\u001b[39mf, fprime\u001b[38;5;241m=\u001b[39mfprime)\n\u001b[0;32m    310\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m xx, yy, bb, uu \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(XD, yD, betas, u)\n\u001b[0;32m    311\u001b[0m     ]\n\u001b[1;32m--> 312\u001b[0m     new_betas \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[43mda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnew_betas\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    314\u001b[0m     beta_hat \u001b[38;5;241m=\u001b[39m over_relax \u001b[38;5;241m*\u001b[39m new_betas \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m over_relax) \u001b[38;5;241m*\u001b[39m z\n\u001b[0;32m    316\u001b[0m     \u001b[38;5;66;03m#  z-update step\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\marij\\miniconda3\\envs\\research_project_dask\\Lib\\site-packages\\dask\\base.py:664\u001b[0m, in \u001b[0;36mcompute\u001b[1;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[0;32m    661\u001b[0m     postcomputes\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_postcompute__())\n\u001b[0;32m    663\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m shorten_traceback():\n\u001b[1;32m--> 664\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repack([f(r, \u001b[38;5;241m*\u001b[39ma) \u001b[38;5;28;01mfor\u001b[39;00m r, (f, a) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[1;32mc:\\Users\\marij\\miniconda3\\envs\\research_project_dask\\Lib\\queue.py:180\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m remaining \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[0;32m    179\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m--> 180\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_empty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    181\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get()\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnot_full\u001b[38;5;241m.\u001b[39mnotify()\n",
      "File \u001b[1;32mc:\\Users\\marij\\miniconda3\\envs\\research_project_dask\\Lib\\threading.py:359\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    358\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 359\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    360\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    361\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "from dask_ml.linear_model import LinearRegression, LogisticRegression\n",
    "from dask_ml.xgboost import XGBClassifier\n",
    "from dask_ml.cluster import KMeans\n",
    "from time import perf_counter\n",
    "\n",
    "res = np.zeros((3, 3, 10)) # Size, model, iteration\n",
    "for i in range(10):\n",
    "    for j, size in enumerate([\"small\", \"medium\", \"large\"]):\n",
    "        # Prep data\n",
    "        print(f\"{size.capitalize()} data\")\n",
    "        dda = dd.read_parquet(fr\"C:\\Users\\marij\\Documents\\GitHub\\732A76_Research_Project\\Data\\{size}.parquet\").repartition(npartitions=[1, 75, 175][j]).to_dask_array(lengths=True)\n",
    "        print(f\"{len(dda.chunks[0])} partitions\")\n",
    "        \n",
    "        X = dda[:, 1:]\n",
    "        y = dda[:, 0]\n",
    "\n",
    "        # Linear regression\n",
    "        lin_reg = LinearRegression()\n",
    "\n",
    "        start_time = perf_counter()   \n",
    "        lin_reg.fit(X, y)\n",
    "        end_time = perf_counter()\n",
    "        \n",
    "        res[j, 0, i] = end_time - start_time\n",
    "        \n",
    "        # Logistic regression\n",
    "        log_reg = LogisticRegression()\n",
    "        \n",
    "        start_time = perf_counter()\n",
    "        log_reg.fit(X, y)\n",
    "        end_time = perf_counter()\n",
    "\n",
    "        res[j, 1, i] = end_time - start_time\n",
    "\n",
    "        # Decision trees\n",
    "        # xgb = XGBClassifier()\n",
    "\n",
    "        # start_time = perf_counter()\n",
    "        # xgb.fit(X, y)\n",
    "        # end_time = perf_counter()\n",
    "\n",
    "        # print(f\"\\tDecision trees: {end_time - start_time:.3f}\")\n",
    "        \n",
    "        # KMeans\n",
    "        kmeans = KMeans(n_clusters=2)\n",
    "\n",
    "        start_time = perf_counter()\n",
    "        kmeans.fit(X)\n",
    "        end_time = perf_counter()\n",
    "\n",
    "        res[j, 2, i] = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "small\n",
      "linear regression: 91.576\n",
      "logistic regression: 98.618\n",
      "k-means: 157.425\n",
      "medium\n",
      "linear regression: 1732.945\n",
      "logistic regression: 1777.468\n",
      "k-means: 128.901\n",
      "large\n",
      "linear regression: 3488.985\n",
      "logistic regression: 3565.304\n",
      "k-means: 251.946\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    size = [\"small\", \"medium\", \"large\"][i]\n",
    "    print(size)\n",
    "    for j in range(3):\n",
    "        model = [\"linear regression\", \"logistic regression\", \"k-means\"][j]\n",
    "        print(f\"{model}: {res[i, j, :][res[i, j, :] != 0].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([236.2924066, 257.2993148, 234.6612128, 279.5303539,   0.       ,\n",
       "         0.       ,   0.       ,   0.       ,   0.       ,   0.       ])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[i, j, :][res[i, j, :] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1125"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research_project_dask",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
